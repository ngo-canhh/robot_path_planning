{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/ngocanhh/Documents/Study/tinhToanTienHoa/Lab_Robot/rrt_orca/data/avoidance_dataset.pkl'\n",
    "MODEL_DIR = '/Users/ngocanhh/Documents/Study/tinhToanTienHoa/Lab_Robot/rrt_ml/utils/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7860"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_data = pickle.load(open(DATA_DIR, 'rb'))\n",
    "len(collection_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cấu trúc của 1 phần tử trong collection data\n",
    "```python\n",
    "(state, action)\n",
    "```\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "1.  **`state` (Trạng thái):**\n",
    "    *   **Kiểu dữ liệu:** Là một mảng NumPy (`numpy.ndarray`) với kiểu dữ liệu `np.float32`.\n",
    "    *   **Nội dung:** Đây chính là **bản sao** của `observation` mà controller nhận được từ môi trường *ngay tại thời điểm* nó quyết định cần phải \"chờ\" (`WaitingRule.should_wait()` trả về `True`).\n",
    "    *   **Cấu trúc chi tiết của `state` (dựa trên `IndoorRobotEnv._get_observation`):**\n",
    "        *   Nó là một mảng 1 chiều (flat array).\n",
    "        *   **5 phần tử đầu tiên (`OBS_ROBOT_STATE_SIZE`):** Trạng thái của robot và đích.\n",
    "            *   `state[0]`: `robot_x` (tọa độ x của robot)\n",
    "            *   `state[1]`: `robot_y` (tọa độ y của robot)\n",
    "            *   `state[2]`: `robot_orientation` (hướng của robot, radian)\n",
    "            *   `state[3]`: `goal_x` (tọa độ x của đích)\n",
    "            *   `state[4]`: `goal_y` (tọa độ y của đích)\n",
    "        *   **Các phần tử tiếp theo (chia thành các khối `OBS_OBSTACLE_DATA_SIZE` = 9):** Thông tin về các vật cản được cảm biến phát hiện (tối đa `max_obstacles_in_observation` vật cản).\n",
    "            *   **Khối vật cản thứ `i` (từ 0 đến `max_obstacles_in_observation - 1`):** Nằm ở chỉ số từ `5 + i * 9` đến `5 + (i+1) * 9 - 1`.\n",
    "                *   `state[5 + i*9 + 0]`: `obstacle_x` (tọa độ x của vật cản)\n",
    "                *   `state[5 + i*9 + 1]`: `obstacle_y` (tọa độ y của vật cản)\n",
    "                *   `state[5 + i*9 + 2]`: `shape_type` (số nguyên đại diện loại hình dạng, ví dụ: 0=Circle, 1=Rectangle)\n",
    "                *   `state[5 + i*9 + 3]`: `param1` (ví dụ: radius cho Circle, width cho Rectangle)\n",
    "                *   `state[5 + i*9 + 4]`: `param2` (ví dụ: 0 cho Circle, height cho Rectangle)\n",
    "                *   `state[5 + i*9 + 5]`: `param3` (ví dụ: 0 cho Circle, angle cho Rectangle)\n",
    "                *   `state[5 + i*9 + 6]`: `is_dynamic` (1.0 nếu động, 0.0 nếu tĩnh)\n",
    "                *   `state[5 + i*9 + 7]`: `velocity_x` (thành phần vận tốc x của vật cản động, 0 nếu tĩnh)\n",
    "                *   `state[5 + i*9 + 8]`: `velocity_y` (thành phần vận tốc y của vật cản động, 0 nếu tĩnh)\n",
    "            *   **Padding:** Nếu số vật cản phát hiện được ít hơn `max_obstacles_in_observation`, các khối còn lại sẽ được điền bằng số 0.0.\n",
    "        *   **Tổng độ dài của mảng `state`:** `5 + max_obstacles_in_observation * 9`. Ví dụ, nếu `max_obstacles_in_observation = 10`, độ dài sẽ là `5 + 10 * 9 = 95`.\n",
    "\n",
    "2.  **`action` (Hành động mong muốn):**\n",
    "    *   **Kiểu dữ liệu:** Là một mảng NumPy (`numpy.ndarray`) với kiểu dữ liệu `np.float32`.\n",
    "    *   **Nội dung:** Đây là **bản sao** của `hypothetical_action` được tính toán bởi hàm `_calculate_path_following_action`. Nó đại diện cho hành động (vận tốc dài và vận tốc góc) mà controller *sẽ thực hiện* nếu nó *bỏ qua* quy tắc chờ và chỉ tuân theo logic bám đường và tránh vật cản tĩnh. Đây chính là \"nhãn\" (label) mà Agent cần học để dự đoán.\n",
    "    *   **Cấu trúc chi tiết của `action`:**\n",
    "        *   Nó là một mảng 1 chiều có 2 phần tử.\n",
    "        *   `action[0]`: `target_velocity` (vận tốc dài mục tiêu)\n",
    "        *   `action[1]`: `target_steering_angle` (góc lái mục tiêu / vận tốc góc)\n",
    "\n",
    "**Ví dụ về một phần tử trong `collected_data`:**\n",
    "\n",
    "```python\n",
    "(\n",
    "  # State (np.ndarray, float32, shape=(95,) assuming max_obstacles=10)\n",
    "  np.array([\n",
    "      305.2, 101.8, 1.57, 400.0, 300.0,  # Robot state (x, y, theta, gx, gy)\n",
    "      # Obstacle 1 (Dynamic Circle near robot)\n",
    "      300.0, 150.0, 0.0, 20.0, 0.0, 0.0, 1.0, -2.5, 0.5,\n",
    "      # Obstacle 2 (Static Rectangle further away)\n",
    "      180.0, 150.0, 1.0, 50.0, 30.0, 0.78, 0.0, 0.0, 0.0,\n",
    "      # Obstacle 3...9 (Padded with zeros if not sensed)\n",
    "      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "      # ... (repeat padding block 7 more times)\n",
    "      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "  ], dtype=np.float32),\n",
    "\n",
    "  # Action (np.ndarray, float32, shape=(2,))\n",
    "  np.array([5.5, -0.15], dtype=np.float32) # [target_velocity, target_steering_angle]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7860, 95]), torch.Size([7860, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = zip(*collection_data)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5502, 95]),\n",
       " torch.Size([5502, 2]),\n",
       " torch.Size([1179, 95]),\n",
       " torch.Size([1179, 2]),\n",
       " torch.Size([1179, 95]),\n",
       " torch.Size([1179, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotAvoidanceNetwork(nn.Module):\n",
    "    def __init__(self, obs_robot_state_size, obs_obstacle_data_size):\n",
    "        self.obs_robot_state_size = obs_robot_state_size\n",
    "        self.obs_obstacle_data_size = obs_obstacle_data_size\n",
    "        super(RobotAvoidanceNetwork, self).__init__()\n",
    "\n",
    "        self.state_mlp = nn.Sequential(\n",
    "            nn.Linear(self.obs_robot_state_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.attention_obs_mlp = nn.Sequential(\n",
    "            nn.Linear(self.obs_obstacle_data_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.obs_mlp = nn.Sequential(\n",
    "            nn.Linear(self.obs_obstacle_data_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.final_mlp_out = nn.Sequential(\n",
    "            nn.Linear(16 + 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, observations): # N, obs_robot_state_size + num_obstacles * obs_obstacle_data_size\n",
    "        num_obstacles = int((observations.shape[1] - self.obs_robot_state_size) // self.obs_obstacle_data_size)\n",
    "        robot_state = observations[:, :self.obs_robot_state_size]\n",
    "        obstacle_data = observations[:, self.obs_robot_state_size:]\n",
    "        obstacle_data = obstacle_data.view(-1, num_obstacles, self.obs_obstacle_data_size) # N, num_obstacles, obs_obstacle_data_size\n",
    "\n",
    "        # Robot state\n",
    "        robot_state = self.state_mlp(robot_state) # N, 16\n",
    "\n",
    "        # Obstacle data\n",
    "        obstacle_attention = F.softmax(torch.sum(self.attention_obs_mlp(obstacle_data), dim=2, keepdim=True), dim=1)\n",
    "        obstacle_data = torch.mul(obstacle_data, obstacle_attention) # N, num_obstacles, obs_obstacle_data_size\n",
    "        obstacle_data = self.obs_mlp(obstacle_data) # N, num_obstacles, 16\n",
    "        obstacle_data = torch.sum(obstacle_data, dim=1) # N, 16\n",
    "        \n",
    "        # Concatenate robot state and obstacle data\n",
    "        x = torch.cat((robot_state, obstacle_data), dim=1)\n",
    "        x = self.final_mlp_out(x)\n",
    "        return x\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 9.5112\n",
      "Val Loss: 9.4679\n",
      "Epoch [200/1000], Loss: 7.3942\n",
      "Val Loss: 7.4129\n",
      "Epoch [300/1000], Loss: 5.9024\n",
      "Val Loss: 6.1053\n",
      "Epoch [400/1000], Loss: 4.8746\n",
      "Val Loss: 5.2573\n",
      "Epoch [500/1000], Loss: 4.0401\n",
      "Val Loss: 4.4037\n",
      "Epoch [600/1000], Loss: 3.5678\n",
      "Val Loss: 3.9946\n",
      "Epoch [700/1000], Loss: 3.2054\n",
      "Val Loss: 3.6302\n",
      "Epoch [800/1000], Loss: 2.9669\n",
      "Val Loss: 3.3599\n",
      "Epoch [900/1000], Loss: 2.9042\n",
      "Val Loss: 3.2180\n",
      "Epoch [1000/1000], Loss: 2.7086\n",
      "Val Loss: 3.1137\n"
     ]
    }
   ],
   "source": [
    "model = RobotAvoidanceNetwork(5, 9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "# Training\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred = model(X_val)\n",
    "            val_loss = loss_fn(y_val_pred, y_val)\n",
    "            print(f'Val Loss: {val_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 1.5124\n",
      "Val Loss: 1.8702\n",
      "Epoch [200/1000], Loss: 1.6149\n",
      "Val Loss: 1.8531\n",
      "Epoch [300/1000], Loss: 1.5129\n",
      "Val Loss: 1.8346\n",
      "Epoch [400/1000], Loss: 1.5060\n",
      "Val Loss: 1.8935\n",
      "Epoch [500/1000], Loss: 1.8517\n",
      "Val Loss: 2.3077\n",
      "Epoch [600/1000], Loss: 1.4875\n",
      "Val Loss: 1.7974\n",
      "Epoch [700/1000], Loss: 1.8392\n",
      "Val Loss: 2.1809\n",
      "Epoch [800/1000], Loss: 1.3245\n",
      "Val Loss: 1.6882\n",
      "Epoch [900/1000], Loss: 1.6711\n",
      "Val Loss: 1.9928\n",
      "Epoch [1000/1000], Loss: 1.3632\n",
      "Val Loss: 1.7679\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred = model(X_val)\n",
    "            val_loss = loss_fn(y_val_pred, y_val)\n",
    "            print(f'Val Loss: {val_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.8622\n",
      "y_pred: tensor([[-5.4417, -2.3107],\n",
      "        [ 1.6189,  1.8348],\n",
      "        [-1.9868, -1.0744],\n",
      "        [-1.3839, -3.2124],\n",
      "        [-4.9674,  5.6096]])\n",
      "y_test: tensor([[-5.0051,  0.5845],\n",
      "        [ 1.8241,  2.2940],\n",
      "        [-1.4257, -0.8324],\n",
      "        [-1.0017, -2.4661],\n",
      "        [-5.6852,  5.6240]])\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = loss_fn(y_pred, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    print(f'y_pred: {y_pred[:5]}')\n",
    "    print(f'y_test: {y_test[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /Users/ngocanhh/Documents/Study/tinhToanTienHoa/Lab_Robot/rrt_ml/utils/model/robot_avoidance_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_path = path.join(MODEL_DIR, 'robot_avoidance_model.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
